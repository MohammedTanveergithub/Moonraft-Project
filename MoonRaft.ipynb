{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPY0RISf2iKRzGpabYpniAy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohammedTanveergithub/Moonraft-Project/blob/main/MoonRaft.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 1 â€“\n",
        "Title - Challenging Fake Image Detection using GAN Models\n",
        "\n",
        "Detecting fake or manipulated images in today's digital age has become increasingly challenging due to the advancements in Generative Adversarial Networks (GANs). These AI-powered tools have made it easier than ever to create convincing fake images that can deceive both human observers and traditional image analysis techniques. The problem at hand is to develop a robust and effective fake image detection system that can differentiate between genuine and manipulated images generated by GAN models.\n",
        "\n",
        "Objective:\n",
        "Develop a fake image detection system that can distinguish between real and AI generated images.\n",
        "\n",
        "Expected Outcomes:\n",
        "-A well-documented fake image detection system with robustness and high accuracy.\n",
        "-Codebase pushed to GitHub with a well-structured repository.\n",
        "-A comprehensive README file documenting the project's details, setup instructions, and usage guidelines. The GitHub repository link should be shared.\n"
      ],
      "metadata": {
        "id": "zmvvs1z5cEXE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **IMPORTING REQUIRED LIBRARIES**"
      ],
      "metadata": {
        "id": "xF7P0uxSekvL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "95flt8eddhqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LOADING THE DATASET**"
      ],
      "metadata": {
        "id": "ov8jryx2ezQF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CIFAR-10 dataset as real images\n",
        "(x_train_real, _), (_, _) = cifar10.load_data()\n",
        "x_train_real = x_train_real / 255.0  # Normalize pixel values"
      ],
      "metadata": {
        "id": "MJLufaJVd3-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate fake images (simple transformation)\n",
        "# For demonstration purposes, we'll flip the real images horizontally to create \"fake\" images.\n",
        "x_train_fake = np.flip(x_train_real, axis=2)  # Horizontal flip"
      ],
      "metadata": {
        "id": "9rees5Mjd30U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GIVING THE LABELS**"
      ],
      "metadata": {
        "id": "z8mxTh2VfHP5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create labels (0 for real, 1 for fake)\n",
        "y_train_real = np.zeros(x_train_real.shape[0])\n",
        "y_train_fake = np.ones(x_train_fake.shape[0])"
      ],
      "metadata": {
        "id": "tdHxI6UHd3oa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate real and fake data\n",
        "x_train = np.concatenate((x_train_real, x_train_fake), axis=0)\n",
        "y_train = np.concatenate((y_train_real, y_train_fake), axis=0)"
      ],
      "metadata": {
        "id": "IHXlR0SQd3eQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "iyNF5dFRd3T4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a simple CNN model for image classification\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "IwlKJDCGd3KW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "4c_nBk3Sd2_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=64, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SY8O8AFd2xz",
        "outputId": "85a63be3-952b-413f-e9be-659e09644d1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1000/1000 [==============================] - 57s 53ms/step - loss: 0.6940 - accuracy: 0.4981 - val_loss: 0.6931 - val_accuracy: 0.4956\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.6932 - accuracy: 0.4995 - val_loss: 0.6932 - val_accuracy: 0.4956\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.6932 - accuracy: 0.5002 - val_loss: 0.6931 - val_accuracy: 0.5044\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 53s 53ms/step - loss: 0.6932 - accuracy: 0.4993 - val_loss: 0.6932 - val_accuracy: 0.4956\n",
            "Epoch 5/10\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.6932 - accuracy: 0.5003 - val_loss: 0.6932 - val_accuracy: 0.4956\n",
            "Epoch 6/10\n",
            "1000/1000 [==============================] - 51s 51ms/step - loss: 0.6932 - accuracy: 0.5011 - val_loss: 0.6933 - val_accuracy: 0.4956\n",
            "Epoch 7/10\n",
            "1000/1000 [==============================] - 49s 49ms/step - loss: 0.6932 - accuracy: 0.4995 - val_loss: 0.6932 - val_accuracy: 0.4956\n",
            "Epoch 8/10\n",
            "1000/1000 [==============================] - 48s 48ms/step - loss: 0.6932 - accuracy: 0.5010 - val_loss: 0.6932 - val_accuracy: 0.4956\n",
            "Epoch 9/10\n",
            "1000/1000 [==============================] - 47s 47ms/step - loss: 0.6932 - accuracy: 0.5010 - val_loss: 0.6932 - val_accuracy: 0.4956\n",
            "Epoch 10/10\n",
            "1000/1000 [==============================] - 49s 49ms/step - loss: 0.6932 - accuracy: 0.4986 - val_loss: 0.6931 - val_accuracy: 0.5044\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c7e1d8732b0>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test data\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(\"Test Accuracy:\", test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXg6529jeJlu",
        "outputId": "d9551b31-28ca-4ae1-a071-71d09a1116cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "625/625 [==============================] - 7s 10ms/step - loss: 0.6931 - accuracy: 0.5017\n",
            "Test Accuracy: 0.5017499923706055\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Accuracy of the following can be increased by performing Some strategies and improvements like :-\n",
        "\n",
        "Larger and More Diverse Dataset, <br>\n",
        "Data Augmentation,<br>\n",
        "Ensemble Learning,<br>\n",
        "Advanced Model Architectures<br>\n",
        "\n",
        "The reason I did not perform this technique is that my LAPTOP could not handle large amount dataset.**"
      ],
      "metadata": {
        "id": "w9e7JDGp8XWl"
      }
    }
  ]
}